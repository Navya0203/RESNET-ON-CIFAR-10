# RESNET-ON-CIFAR-10
In this project, we proposed a straightforward strategy to engineer Residual networks with fewer than 5M trainable parameters, thereby diminishing their memory requirements: 
Our experiments on the CIFAR10 dataset with custom ResNet architectures involving Squeeze and Activation Blocks and parameter sharing demonstrate that it is possible to maintain good accuracy despite reducing parameters.

## GETTING STARTED

After cloning the repository,follow these steps:

1) Navigate to the main project folder called `Main_Project_Model(checkpoint included)`
2) This contains the Jupyter notebook called `MiniProject_Model(SE_Enhanced_Basic_ResNet)`  and the model checkpoint to reproduce the performance of the model called`lat_model`.
3) You can run the `MiniProject_Model(SE_Enhanced_Basic_ResNet)` to train our custom ResNet and also create predictions on the no-label test dataset.


