# RESNET-ON-CIFAR-10
In this project, we proposed a straightforward strategy to engineer Residual networks with fewer than 5M trainable parameters, thereby diminishing their memory requirements: 
Our experiments on the CIFAR10 dataset with custom ResNet architectures involving Squeeze and Activation Blocks and parameter sharing demonstrate that it is possible to maintain good accuracy despite reducing parameters.

## GETTING STARTED

After cloning the repository, navigate to the main project folder called `Main_Project_Model(checkpoint included)` which contains the Jupyter notebook called `MiniProject_Model(SE_Enhanced_Basic_ResNet)`  and the model checkpoint to reproduce the performance of the model called`lat_model`. 

To generate a predictions CSV by running the notebook, follow these steps:

```bash
git clone https://github.com/your-username/your-repository-name.git
cd your-repository-name
jupyter notebook
```
If you want to check our model performance, you can run 'lat_model' on your own environment. 
